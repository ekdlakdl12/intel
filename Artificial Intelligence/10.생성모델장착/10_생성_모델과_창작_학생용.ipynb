{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. 오토인코더 실습"
      ],
      "metadata": {
        "id": "thPKwZn4st7A"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EJEG5xpysnHF"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input,Dense,Flatten,Reshape,Conv2D,Conv2DTranspose\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# MNIST 데이터를 읽고 신경망에 입력할 준비\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "x_train=x_train.astype('float32')/255.\n",
        "x_test=x_test.astype('float32')/255.\n",
        "x_train=np.reshape(x_train,(len(x_train),28,28,1))\n",
        "x_test=np.reshape(x_test,(len(x_test),28,28,1))\n",
        "\n",
        "zdim=32 # 잠복 공간의 차원\n",
        "\n",
        "# 오토인코더의 인코더 부분 설계\n",
        "encoder_input=Input(shape=(28,28,1))\n",
        "x=Conv2D(32,(3,3),activation='relu',padding='same',strides=(1,1))(encoder_input)\n",
        "x=Conv2D(64,(3,3),activation='relu',padding='same',strides=(2,2))(x)\n",
        "x=Conv2D(64,(3,3),activation='relu',padding='same',strides=(2,2))(x)\n",
        "x=Conv2D(64,(3,3),activation='relu',padding='same',strides=(1,1))(x)\n",
        "x=Flatten()(x)\n",
        "encoder_output=Dense(zdim)(x)\n",
        "model_encoder=Model(encoder_input,encoder_output)\n",
        "model_encoder.summary()\n",
        "\n",
        "# 오토인코더의 디코더 부분 설계\n",
        "decoder_input=Input(shape=(zdim,))\n",
        "x=Dense(3136)(decoder_input)\n",
        "x=Reshape((7,7,64))(x)\n",
        "x=Conv2DTranspose(64,(3,3),activation='relu',padding='same',strides=(1,1))(x)\n",
        "x=Conv2DTranspose(64,(3,3),activation='relu',padding='same',strides=(2,2))(x)\n",
        "x=Conv2DTranspose(32,(3,3),activation='relu',padding='same',strides=(2,2))(x)\n",
        "x=Conv2DTranspose(1,(3,3),activation='relu',padding='same',strides=(1,1))(x)\n",
        "decoder_output=x\n",
        "model_decoder=Model(decoder_input,decoder_output)\n",
        "model_decoder.summary()\n",
        "\n",
        "# 인코더와 디코더를 결합하여 오토인코더 모델 구축\n",
        "############\n",
        "############\n",
        "############\n",
        "\n",
        "# 오토인코더 학습\n",
        "############\n",
        "############\n",
        "\n",
        "# 복원 실험 1: x_test를 복원하는 예측 실험\n",
        "decoded_img=model.predict(x_test)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "n=10\n",
        "plt.figure(figsize=(20, 4))\n",
        "for i in range(n):\n",
        "    plt.subplot(2, n, i+1)\n",
        "    plt.imshow(x_test[i].reshape(28, 28),cmap='gray')\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "    plt.subplot(2, n, i + n+1)\n",
        "    plt.imshow(decoded_img[i].reshape(28, 28),cmap='gray')\n",
        "    plt.xticks([]); plt.yticks([])\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. GAN 구현 실습"
      ],
      "metadata": {
        "id": "bD3l0pfqsxgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.layers import Input,Activation,Dense,Flatten,Reshape,Conv2D,Conv2DTranspose,Dropout,BatchNormalization,UpSampling2D\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.losses import mse\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train,y_train),(x_test,y_test)=mnist.load_data()\n",
        "x_train = (x_train.astype('float32')/255.0)*2.0-1.0 # [-1,1] 구간\n",
        "x_test = (x_test.astype('float32')/255.0)*2.0-1.0\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "batch_siz=64\n",
        "epochs=5000\n",
        "dropout_rate=0.4\n",
        "batch_norm=0.9\n",
        "zdim=100 # 잠복 공간의 차원\n",
        "\n",
        "discriminator_input=Input(shape=(28, 28, 1)) # 분별망 D 설계\n",
        "x=Conv2D(64,(5,5),activation='relu',padding='same',strides=(2,2))(discriminator_input)\n",
        "x=Dropout(dropout_rate)(x)\n",
        "x=Conv2D(64,(5,5),activation='relu',padding='same',strides=(2,2))(x)\n",
        "x=Dropout(dropout_rate)(x)\n",
        "x=Conv2D(128,(5,5),activation='relu',padding='same',strides=(2,2))(x)\n",
        "x=Dropout(dropout_rate)(x)\n",
        "x=Conv2D(128,(5,5),activation='relu',padding='same',strides=(1,1))(x)\n",
        "x=Dropout(dropout_rate)(x)\n",
        "x=Flatten()(x)\n",
        "discriminator_output=Dense(1,activation='sigmoid')(x)\n",
        "discriminator=Model(discriminator_input,discriminator_output)\n",
        "\n",
        "generator_input=Input(shape=(zdim,)) # 생성망 G 설계\n",
        "x=Dense(3136)(generator_input)\n",
        "x=BatchNormalization(momentum=batch_norm)(x)\n",
        "x=Activation('relu')(x)\n",
        "x=Reshape((7,7,64))(x)\n",
        "x=UpSampling2D()(x)\n",
        "x=Conv2D(128,(5,5),padding='same')(x)\n",
        "x=BatchNormalization(momentum=batch_norm)(x)\n",
        "x=Activation('relu')(x)\n",
        "x=UpSampling2D()(x)\n",
        "x=Conv2D(64,(5,5),padding='same')(x)\n",
        "x=BatchNormalization(momentum=batch_norm)(x)\n",
        "x=Activation('relu')(x)\n",
        "x=Conv2D(64,(5,5),padding='same')(x)\n",
        "x=BatchNormalization(momentum=batch_norm)(x)\n",
        "x=Activation('relu')(x)\n",
        "x=Conv2D(1,(5,5),activation='tanh',padding='same')(x)\n",
        "generator_output=x\n",
        "generator=Model(generator_input,generator_output)\n",
        "\n",
        "discriminator.compile(optimizer='Adam',loss='binary_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "############\n",
        "############\n",
        "############\n",
        "############\n",
        "############\n",
        "\n",
        "def train_discriminator(x_train):\n",
        "    c=np.random.randint(0,x_train.shape[0],batch_siz)\n",
        "    real=x_train[c]\n",
        "    discriminator.train_on_batch(real,np.ones((batch_siz,1)))\n",
        "\n",
        "    p=np.random.normal(0,1,(batch_siz,zdim))\n",
        "    fake=generator.predict(p)\n",
        "    discriminator.train_on_batch(fake,np.zeros((batch_siz,1)))\n",
        "\n",
        "def train_generator():\n",
        "    p=np.random.normal(0,1,(batch_siz,zdim))\n",
        "    gan.train_on_batch(p,np.ones((batch_siz,1)))\n",
        "\n",
        "for i in range(epochs+1): # 학습을 수행\n",
        "    train_discriminator(x_train)\n",
        "    train_generator()\n",
        "    if(i%100==0): # 학습 도중 100세대마다 중간 상황 출력\n",
        "        plt.figure(figsize=(20, 4))\n",
        "        plt.suptitle('epoch '+str(i))\n",
        "        for k in range(20):\n",
        "            plt.subplot(2,10,k+1)\n",
        "            img=generator.predict(np.random.normal(0,1,(1,zdim)))\n",
        "            plt.imshow(img[0].reshape(28,28),cmap='gray')\n",
        "            plt.xticks([]); plt.yticks([])\n",
        "        plt.show()\n",
        "\n",
        "imgs=generator.predict(np.random.normal(0,1,(50,zdim)))\n",
        "plt.figure(figsize=(20,10)) # 학습을 마친 후 50개 샘플을 생성하여 출력\n",
        "for i in range(50):\n",
        "    plt.subplot(5,10,i+1)\n",
        "    plt.imshow(imgs[i].reshape(28,28),cmap='gray')\n",
        "    plt.xticks([]); plt.yticks([])"
      ],
      "metadata": {
        "id": "WWBTF_iOsxwT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}